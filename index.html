<!DOCTYPE html>
<html lang="en">
  <head>
    <title>WMB</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script
      src="https://kit.fontawesome.com/f8ddf9854a.js"
      crossorigin="anonymous"
    ></script>
    <meta charset="utf-8" />
    <meta
      name="description"
      content="A Multi-discipline and Multi-domain Benchmark for Expert World Models"
    />
    <meta
      name="keywords"
      content="WMB, World Model, World Model Evaluation, Vision Language Model, Large Language Model, Large Multimodal Model, artificial intelligence, AI, AGI, artificial general intelligence"
    />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>
      WorldModelBench: Judging Video Generation Models As World Models
    </title>

    <link rel="icon" href="./static/images/mmmu_icon2.png" />

    <link
      href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
      rel="stylesheet"
    />

    <link rel="stylesheet" href="./static/css/bulma.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
    <link rel="stylesheet" href="./static/css/index.css" />
    <script
      src="https://kit.fontawesome.com/fff5b27ec1.js"
      crossorigin="anonymous"
    ></script>
    <!-- <script src="https://kit.fontawesome.com/eaf1856e6f.js" crossorigin="anonymous"></script> -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
  </head>
  <body>
    <nav class="navbar" role="navigation" aria-label="main navigation">
      <div class="navbar-brand">
        <a
          role="button"
          class="navbar-burger"
          aria-label="menu"
          aria-expanded="false"
        >
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
        </a>
      </div>
      <div class="navbar-menu">
        <div class="navbar-start" style="flex-grow: 1; justify-content: center">
          <div class="navbar-item has-dropdown is-hoverable">
            <a class="navbar-link"> More Research </a>
            <div class="navbar-dropdown">
              <a
                class="navbar-item"
                href="https://huggingface.co/datasets/MMMU/MMMU_Pro"
              >
                <b>MMMU-Pro</b>
                <span style="font-size: 18px; display: inline; margin-left: 5px"
                  >ðŸ”¥</span
                >
              </a>
            </div>
          </div>
        </div>
      </div>
    </nav>

    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title is-bold">
                <img
                  src="static/images/mmmu_icon2.png"
                  style="width: 1em; vertical-align: middle"
                  alt="Logo"
                />
                <span class="wmb" style="vertical-align: middle">WMB</span>
              </h1>
              <h2 class="subtitle is-3 publication-subtitle">
                A Massive Multi-discipline and Multi-domain Benchmark for Expert
                World Models
              </h2>
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <a
                    href="https://dachengli1.github.io/"
                    style="text-decoration: none; color: inherit"
                    >Dacheng Li*â€ </a
                  >,
                </span>
                <span class="author-block">
                  <a
                    href="https://seerkfang.github.io/"
                    style="text-decoration: none; color: inherit"
                    >Yunhao Fang*â€ </a
                  >,
                </span>
                <br />
                <span class="author-block">Yukang Chen,</span>
                <span class="author-block">Shuo Yang,</span>
                <span class="author-block">Shiyi Cao,</span>
                <span class="author-block">Justin Wong,</span><br />
                <span class="author-block">Xiaolong Wang,</span>
                <span class="author-block">Hongxu Yin,</span>
                <span class="author-block">Joseph E. Gonzalez,</span>
                <span class="author-block">Ion Stoica,</span>
                <span class="author-block">
                  <a
                    href="https://hanlab.mit.edu/songhan/"
                    style="text-decoration: none; color: inherit"
                    >Song Han*</a
                  >
                </span>
                <span class="author-block">
                  <a
                    href="https://research.nvidia.com/person/yao-lu-jason"
                    style="text-decoration: none; color: inherit"
                    >Jason Lu*â€ </a
                  >
                </span>
              </div>

              <br />

              <div class="is-size-5 publication-authors">
                <span class="author-block"><b>WMB Team</b></span>
              </div>

              <br />
              <div class="is-size-5 publication-authors">
                <span class="author-block">*Core Contributors</span><br />
                <span class="author-block">â€ Corresponding to:</span>
                <span class="author-block"
                  ><a href="mailto:dacheng177@berkeley.edu"
                    >dacheng177@berkeley.edu</a
                  >,</span
                >
                <span class="author-block"
                  ><a href="mailto:seerkfang@gmail.com">seerkfang@gmail.com</a
                  >,</span
                >
                <span class="author-block"
                  ><a href="mailto:">jasonlu@nvidia.com</a></span
                >
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <span class="link-block">
                    <a
                      href="https://arxiv.org/abs/2311.16502"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a
                      href="https://huggingface.co/datasets/MMMU/MMMU"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon" style="font-size: 18px">ðŸ¤—</span>
                      <span>MMMU</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a
                      href="https://github.com/MMMU-Benchmark/MMMU"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a
                      href="#leaderboard"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon has-text-white">
                        <i class="fa-solid fa-trophy"></i>
                      </span>
                      <span>Leaderboard</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a
                      href="https://eval.ai/web/challenges/challenge-page/2179/overview"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon has-text-white">
                        <i class="fa-solid fa-medal"></i>
                      </span>
                      <span>EvalAI</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a
                      href="https://twitter.com/xiangyue96/status/1729698316554801358"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon has-text-white">
                        <i class="fa-brands fa-x-twitter"></i>
                      </span>
                      <span>Twitter</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="hero teaser">
      <div class="container is-max-desktop has-text-centered">
        <img src="static/images/wmb/overview.jpg" alt="geometric reasoning" />
        <p>
          Overview of the MMMU dataset. MMMU presents four challenges: 1)
          <b>comprehensiveness</b>: 11.5K college-level problems across six
          broad disciplines and 30 college subjects; 2) highly
          <b>heterogeneous</b> image types; 3) <b>interleaved</b> text and
          images; 4) <b>expert-level</b> perception and reasoning rooted in deep
          subject knowledge.
        </p>
      </div>
    </section>

    <section class="section">
      <div class="container" style="margin-bottom: 2vh">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">ðŸ””News</h2>
            <div class="content has-text-justified">
              <p>
                <b
                  >ðŸ”¥[2024-09-05] Introducing
                  <a href="https://arxiv.org/abs/2409.02813">MMMU-Pro</a>, a
                  robust version of MMMU benchmark for multimodal AI evaluation!
                  ðŸš€</b
                >
              </p>
              <p>
                <b
                  >ðŸš€[2024-01-31]: We added Human Expert performance on the
                  <a href="#leaderboard">Leaderboard</a>!ðŸŒŸ</b
                >
              </p>
              <p>
                <b
                  >ðŸ”¥[2023-12-04]: Our evaluation server for the test set is now
                  available on
                  <a
                    href="https://eval.ai/web/challenges/challenge-page/2179/overview"
                    ><b>EvalAI</b></a
                  >. We welcome all submissions and look forward to your
                  participation! ðŸ˜†</b
                >
              </p>
            </div>
            <h2 class="title is-3">Introduction</h2>
            <div class="content has-text-justified">
              <p>
                We introduce MMMU: a new benchmark designed to evaluate
                multimodal models on massive multi-discipline tasks demanding
                college-level subject knowledge and deliberate reasoning. MMMU
                includes <b>11.5K</b> meticulously collected multimodal
                questions from college exams, quizzes, and textbooks, covering
                six core disciplines: Art & Design, Business, Science, Health &
                Medicine, Humanities & Social Science, and Tech & Engineering.
                These questions span <b>30</b> subjects and
                <b>183</b> subfields, comprising 30 highly heterogeneous image
                types, such as charts, diagrams, maps, tables, music sheets, and
                chemical structures. Unlike existing benchmarks, MMMU focuses on
                advanced perception and reasoning with domain-specific
                knowledge, challenging models to perform tasks akin to those
                faced by experts. Our evaluation of 14 open-source LMMs and the
                proprietary GPT-4V(ision) highlights the substantial challenges
                posed by MMMU. Even the advanced GPT-4V only achieves a 56%
                accuracy, indicating significant room for improvement. We
                believe MMMU will stimulate the community to build
                next-generation multimodal foundation models towards expert
                artificial general intelligence.
              </p>
            </div>
          </div>
        </div>
        <!--/ Abstract. -->
      </div>
    </section>

    <!-- DATASET SECTION -->
    <section class="hero is-light is-small">
      <div class="hero-body has-text-centered">
        <h1 class="title is-1 mmmu">
          <img
            src="static/images/mmmu_icon2.png"
            alt="Logo"
            class="mmmu-logo"
          />
          <span class="mmmu">MMMU Benchmark</span>
        </h1>
      </div>
    </section>

    <section class="section">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Overview</h2>
            <div class="content has-text-justified">
              <p>
                We introduce the Massive Multi-discipline Multimodal
                Understanding and Reasoning (MMMU) benchmark, a novel benchmark
                meticulously curated to assess the expert-level multimodal
                understanding capability of foundation models across a broad
                scope of tasks. Covering subjects across disciplines, including
                Art, Business, Health & Medicine, Science, Humanities & Social
                Science, and Tech & Engineering, and over subfields. The
                detailed subject coverage and statistics are detailed in the
                figure. The questions in our benchmark were manually collected
                by a team of college students (including coauthors) from various
                disciplines and subjects, drawing from online sources,
                textbooks, and lecture materials.
              </p>
              <img
                src="static/images/mmlu_example.Jpeg"
                alt="algebraic reasoning"
                class="center"
              />
              <br />
              <p>
                MMMU is designed to measure three essential skills in LMMs:
                perception, knowledge, and reasoning. Our aim is to evaluate how
                well these models can not only perceive and understand
                information across different modalities but also apply reasoning
                with subject-specific knowledge to derive the solution.
              </p>
              <p>
                Our MMMU benchmark introduces key challenges to multimodal
                foundation models, as detailed in a figure. Among these, we
                particularly highlight the challenge stemming from the
                requirement for both expert-level visual perceptual abilities
                and deliberate reasoning with subject-specific knowledge. This
                challenge is vividly illustrated through our tasks, which not
                only demand the processing of various heterogeneous image types
                but also necessitate a model's adeptness in using
                domain-specific knowledge to deeply understand both the text and
                images and to reason. This goes significantly beyond basic
                visual perception, calling for an advanced approach that
                integrates advanced multimodal analysis with domain-specific
                knowledge.
              </p>
            </div>
          </div>
        </div>

        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Comparisons with Existing Benchmarks</h2>
            <div class="content has-text-justified">
              <p>
                To further distinguish the difference between <i>dataset</i> and
                other existing ones, we elaborate the benchmark details in
                Figure. From the <i>breadth</i> perspective, the prior
                benchmarks are heavily focused on daily knowledge and common
                sense. The covered image format is also limited. Our benchmark
                aims to cover college-level knowledge with 30 image formats
                including diagrams, tables, charts, chemical structures, photos,
                paintings, geometric shapes, music sheets, medical images, etc.
                In the <i>depth</i> aspect, the previous benchmarks normally
                require commonsense knowledge or simple physical or temporal
                reasoning. In contrast, our benchmark requires deliberate
                reasoning with college-level subject knowledge.
              </p>
              <div class="content has-text-centered">
                <img
                  src="static/images/compare.Jpeg"
                  alt="algebraic reasoning"
                  class="center"
                />
                <p>
                  Sampled MMMU examples from each discipline. The questions and
                  images need expert-level knowledge to understand and reason.
                </p>
              </div>
            </div>
          </div>
        </div>

        <div class="columns is-centered m-6">
          <div class="column is-full has-text-centered content">
            <h2 class="title is-3">Statistics</h2>
            <div class="carousel results-carousel">
              <div class="box m-5">
                <div class="content has-text-centered">
                  <img
                    src="static/images/mmmu_subject_distribution.Jpeg"
                    alt="algebraic reasoning"
                    width="95%"
                  />
                  <p>
                    Sampled MMMU examples from each discipline. The questions
                    and images need expert-level knowledge to understand and
                    reason.
                  </p>
                </div>
              </div>
              <div class="box m-5">
                <div class="content has-text-centered">
                  <img
                    src="static/images/statistics.png"
                    alt="arithmetic reasoning"
                    width="40%"
                  />
                  <p>Key statistics of the MMMU benchmark</p>
                </div>
              </div>
              <div class="box m-5">
                <div class="content has-text-centered">
                  <img
                    src="static/images/image_type_count.png"
                    alt="arithmetic reasoning"
                    width="80%"
                  />
                  <p>Distribution of image types in the MMMU dataset</p>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- RESULTS SECTION -->
    <section class="hero is-light is-small">
      <div class="hero-body has-text-centered">
        <h1 class="title is-1 mmmu">Experiment Results</h1>
      </div>
    </section>

    <section class="section">
      <div class="container">
        <!-------------------------------------------------------------------- RESULTS SECTION -------------------------------------------------------------------->
        <div class="columns is-centered m-6">
          <div class="column is-full has-text-centered content">
            <h2 class="title is-3" id="leaderboard">Leaderboard</h2>
            <div class="content has-text-justified">
              <p>
                We evaluate various models including LLMs and LMMs. In each
                type, we consider both closed- and open-source models. Our
                evaluation is conducted under a zero-shot setting to assess the
                capability of models to generate accurate answers without
                fine-tuning or few-shot demonstrations on our benchmark. For all
                models, we use the default prompt provided by each model for
                multi-choice or open QA, if available. If models do not provide
                prompts for task types in MMMU, we conduct prompt engineering on
                the validation set and use the most effective prompt for the
                later zero-shot experiment.
              </p>
            </div>
            <br />
            <div class="model-labels-container">
              <span class="leaderboard-label human_expert">Human Expert</span>
              <span class="leaderboard-label open_source">Open-Source</span>
              <span class="leaderboard-label proprietary">Proprietary</span>
            </div>
            <br />
            <div class="content has-text-centered">
              <p>
                Click on MMMU-Pro, MMMU (Val) or MMMU (Test) to expand detailed
                results.
              </p>
            </div>
            <div class="leaderboard-container">
              <div class="table-wrapper">
                <table id="mmmu-table">
                  <thead>
                    <tr>
                      <th
                        colspan="3"
                        class="reset-cell clickable"
                        style="text-align: center"
                      >
                        Reset
                      </th>
                      <th class="pro-details-cell clickable" colspan="1">
                        MMMU-Pro
                      </th>
                      <th class="val-details-cell clickable" colspan="1">
                        MMMU(Val)
                      </th>
                      <th class="test-details-cell clickable" colspan="1">
                        MMMU(Test)
                      </th>
                    </tr>
                    <tr>
                      <th class="sortable clickable" data-sort="string">
                        Name
                      </th>
                      <th class="clickable" data-sort="string">Size</th>
                      <th class="sortable clickable" data-sort="date">Date</th>
                      <th
                        class="sortable clickable pro-overall"
                        data-sort="number"
                      >
                        Overall
                      </th>
                      <th
                        class="hidden pro-details sortable clickable"
                        data-sort="number"
                      >
                        Vision
                      </th>
                      <th
                        class="hidden pro-details sortable clickable"
                        data-sort="number"
                      >
                        Standard
                      </th>
                      <th
                        class="sortable clickable val-overall"
                        data-sort="number"
                      >
                        Overall
                      </th>
                      <th
                        class="hidden val-details sortable clickable"
                        data-sort="number"
                      >
                        Art & Design
                      </th>
                      <th
                        class="hidden val-details sortable clickable"
                        data-sort="number"
                      >
                        Business
                      </th>
                      <th
                        class="hidden val-details sortable clickable"
                        data-sort="number"
                      >
                        Science
                      </th>
                      <th
                        class="hidden val-details sortable clickable"
                        data-sort="number"
                      >
                        Health & Medicine
                      </th>
                      <th
                        class="hidden val-details sortable clickable"
                        data-sort="number"
                      >
                        Human. & Social Sci.
                      </th>
                      <th
                        class="hidden val-details sortable clickable"
                        data-sort="number"
                      >
                        Tech & Eng.
                      </th>
                      <th
                        class="sortable clickable test-overall"
                        data-sort="number"
                      >
                        Overall
                      </th>
                      <th
                        class="hidden test-details sortable clickable"
                        data-sort="number"
                      >
                        Art & Design
                      </th>
                      <th
                        class="hidden test-details sortable clickable"
                        data-sort="number"
                      >
                        Business
                      </th>
                      <th
                        class="hidden test-details sortable clickable"
                        data-sort="number"
                      >
                        Science
                      </th>
                      <th
                        class="hidden test-details sortable clickable"
                        data-sort="number"
                      >
                        Health & Medicine
                      </th>
                      <th
                        class="hidden test-details sortable clickable"
                        data-sort="number"
                      >
                        Human. & Social Sci.
                      </th>
                      <th
                        class="hidden test-details sortable clickable"
                        data-sort="number"
                      >
                        Tech & Eng.
                      </th>
                    </tr>
                  </thead>
                  <tbody>
                    <!-- Table body will be populated dynamically -->
                  </tbody>
                </table>
                <p class="test-desc">
                  Overall results of different models on the MMMU leaderboard.
                  The best-performing model in each category is <b>in-bold</b>,
                  and the second best is <u>underlined</u>. *: results provided
                  by the authors.
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- @PAN TODO: bibtex -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title is-3 has-text-centered">BibTeX</h2>
        <pre><code>
          @inproceedings{yue2023mmmu,
            title={MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI},
            author={Xiang Yue and Yuansheng Ni and Kai Zhang and Tianyu Zheng and Ruoqi Liu and Ge Zhang and Samuel Stevens and Dongfu Jiang and Weiming Ren and Yuxuan Sun and Cong Wei and Botao Yu and Ruibin Yuan and Renliang Sun and Ming Yin and Boyuan Zheng and Zhenzhu Yang and Yibo Liu and Wenhao Huang and Huan Sun and Yu Su and Wenhu Chen},
            booktitle={Proceedings of CVPR},
            year={2024},
          }
    </code></pre>
      </div>
    </section>

    <footer class="footer">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is website adapted from
              <a href="https://nerfies.github.io/">Nerfies</a> and
              <a href="https://mmmu-benchmark.github.io/">MMMU</a>, licensed
              under a
              <a
                rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/"
                >Creative Commons Attribution-ShareAlike 4.0 International
                License</a
              >.
            </p>
          </div>
        </div>
      </div>
    </footer>
  </body>
</html>
